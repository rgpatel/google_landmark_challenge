{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Landmark Recognition\n",
    "\n",
    "Note: Although the Inception model was trained here, we have not included it in the final report as the aim was to only include top three models. Therefore, its accuracy is not shown here. However, it can be calculated in a similar manner.\n",
    "\n",
    "## Step 1: Import Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 loaded\n",
      "VGG19 loaded\n",
      "Resnet loaded\n",
      "Inception loaded\n"
     ]
    }
   ],
   "source": [
    "train_VGG16 = np.load('Train.npz')['arr_0']\n",
    "valid_VGG16 = np.load('Valid.npz')['arr_0']\n",
    "test_VGG16 = np.load('Test.npz')['arr_0']\n",
    "\n",
    "print('VGG16 loaded')\n",
    "\n",
    "train_VGG19 = np.load('Train_vgg19.npz')['arr_0']\n",
    "valid_VGG19 = np.load('Valid_vgg19.npz')['arr_0']\n",
    "test_VGG19 = np.load('Test_vgg19.npz')['arr_0']\n",
    "\n",
    "print('VGG19 loaded')\n",
    "\n",
    "train_Resnet = np.load('Train_resnet.npz')['arr_0']\n",
    "valid_Resnet = np.load('Valid_resnet.npz')['arr_0']\n",
    "test_Resnet = np.load('Test_resnet.npz')['arr_0']\n",
    "\n",
    "print('Resnet loaded')\n",
    "\n",
    "train_inception = np.load('Train_inception.npz')['arr_0']\n",
    "valid_inception = np.load('Valid_inception.npz')['arr_0']\n",
    "test_inception = np.load('Test_inception.npz')['arr_0']\n",
    "\n",
    "print('Inception loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Architecture\n",
    "\n",
    "The model uses the the pre-trained model as a fixed feature extractor, where the last convolutional output is fed as input to our model.  We only add a global average pooling layer and a fully connected layer, where the latter contains one node for each category and is equipped with a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guevarau\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               102600    \n",
      "=================================================================\n",
      "Total params: 102,600\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               102600    \n",
      "=================================================================\n",
      "Total params: 102,600\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_3 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               409800    \n",
      "=================================================================\n",
      "Total params: 409,800\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_4 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               409800    \n",
      "=================================================================\n",
      "Total params: 409,800\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# VGG16 Model\n",
    "\n",
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dense(200, activation='softmax'))\n",
    "\n",
    "VGG16_model.summary()\n",
    "\n",
    "# VGG19 Model\n",
    "\n",
    "VGG19_model = Sequential()\n",
    "VGG19_model.add(GlobalAveragePooling2D(input_shape=train_VGG19.shape[1:]))\n",
    "VGG19_model.add(Dense(200, activation='softmax'))\n",
    "\n",
    "VGG19_model.summary()\n",
    "\n",
    "# Resenet Model\n",
    "\n",
    "resnet_model = Sequential()\n",
    "resnet_model.add(GlobalAveragePooling2D(input_shape=train_Resnet.shape[1:]))\n",
    "resnet_model.add(Dense(200, activation='softmax'))\n",
    "\n",
    "resnet_model.summary()\n",
    "\n",
    "# Inception Model\n",
    "\n",
    "inception_model = Sequential()\n",
    "inception_model.add(GlobalAveragePooling2D(input_shape=train_inception.shape[1:]))\n",
    "inception_model.add(Dense(200, activation='softmax'))\n",
    "\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compile the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "VGG19_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "resnet_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "inception_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pandas as pd\n",
    "train_targets = pd.read_csv('train_real.csv')['landmark_id']\n",
    "valid_targets = pd.read_csv('valid_real.csv')['landmark_id']\n",
    "test_targets = pd.read_csv('test_real.csv')['landmark_id']\n",
    "\n",
    "un = np.unique(train_targets)\n",
    "\n",
    "j=0\n",
    "for c,ii in enumerate(un):\n",
    "    train_targets = train_targets.replace(ii,j)\n",
    "    valid_targets = valid_targets.replace(ii,j)\n",
    "    test_targets = test_targets.replace(ii,j)\n",
    "    j = j + 1\n",
    "\n",
    "\n",
    "train_targets2 = np_utils.to_categorical(np.array(train_targets),200)\n",
    "valid_targets2 = np_utils.to_categorical(np.array(valid_targets),200)\n",
    "test_targets2 = np_utils.to_categorical(np.array(test_targets),200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 trained\n",
      "VGG19 trained\n",
      "Resnet trained\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.best.VGG16.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, train_targets2, \n",
    "          validation_data=(valid_VGG16, valid_targets2),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "print('VGG16 trained')\n",
    "\n",
    "checkpointer1 = ModelCheckpoint(filepath='weights.best.VGG19.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "VGG19_model.fit(train_VGG19, train_targets2, \n",
    "          validation_data=(valid_VGG19, valid_targets2),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer1], verbose=0)\n",
    "\n",
    "print('VGG19 trained')\n",
    "\n",
    "checkpointer2 = ModelCheckpoint(filepath='weights.best.resnet.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "resnet_model.fit(train_Resnet, train_targets2, \n",
    "          validation_data=(valid_Resnet, valid_targets2),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer2], verbose=0)\n",
    "\n",
    "print('Resnet trained')\n",
    "\n",
    "#checkpointer3 = ModelCheckpoint(filepath='weights.best.inception.hdf5', \n",
    "#                               verbose=0, save_best_only=True)\n",
    "\n",
    "#inception_model.fit(train_inception, train_targets2, \n",
    "#          validation_data=(valid_inception, valid_targets2),\n",
    "#          epochs=20, batch_size=20, callbacks=[checkpointer3], verbose=0)\n",
    "\n",
    "# print('Inception trained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.load_weights('weights.best.VGG16.hdf5')\n",
    "\n",
    "VGG19_model.load_weights('weights.best.VGG19.hdf5')\n",
    "\n",
    "resnet_model.load_weights('weights.best.resnet.hdf5')\n",
    "\n",
    "#inception_model.load_weights('weights.best.inception.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Test accuracy: 88.8176%\n",
      "VGG19 Test accuracy: 89.6731%\n",
      "Resnet Test accuracy: 97.0364%\n"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "\n",
    "VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets2, axis=1))/len(VGG16_predictions)\n",
    "print('VGG16 Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "# VGG19\n",
    "\n",
    "VGG19_predictions = [np.argmax(VGG19_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG19]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(VGG19_predictions)==np.argmax(test_targets2, axis=1))/len(VGG19_predictions)\n",
    "print('VGG19 Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "# Resnet\n",
    "\n",
    "resnet_predictions = [np.argmax(resnet_model.predict(np.expand_dims(feature, axis=0))) for feature in test_Resnet]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(resnet_predictions)==np.argmax(test_targets2, axis=1))/len(resnet_predictions)\n",
    "print('Resnet Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "# Inception\n",
    "\n",
    "#inception_predictions = [np.argmax(inception_model.predict(np.expand_dims(feature, axis=0))) for feature in test_inception]\n",
    "\n",
    "#test_accuracy = 100*np.sum(np.array(inception_predictions)==np.argmax(test_targets2, axis=1))/len(inception_predictions)\n",
    "#print('Inception Test accuracy: %.4f%%' % test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a2cb22358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {'VGG16':[82.3709, 82.432, 82.3709, 82.5848, 82.4931, 82.5542, 83.257, 86.5872, 88.6037, 88.8176], \n",
    "       'VGG19': [88.3288, 89.4898, 89.3064, 89.337, 89.3064, 89.3981, 89.5509, 89.5203, 89.5509, 89.6731],\n",
    "       'Resnet': [96.4253, 96.7919, 96.517, 96.7614, 96.9447, 96.7614, 97.0058, 97.0058, 97.0364, 97.0364]}\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "ax = df.boxplot(column=['VGG16', 'VGG19', 'Resnet'], grid=False)\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "plt.savefig('boxplot.png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
